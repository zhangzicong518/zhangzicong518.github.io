{"basics":{"name (en)":"Zicong Zhang","name (zh)":"张子聪","email":"zhangzicong@sjtu.edu.cn","brief":"second-year undergraduate student from John Hopcroft Class, Zhiyuan College, Shanghai Jiao Tong University, majoring in Computer Science"},"education":[{"institution":"Shanghai Jiao Tong University","location":"Shanghai, China","url":"https://www.sjtu.edu.cn/","studyType":"undergraduate","startDate":"2023-09-01","endDate":"2027-06-30(Expected)","area":"Computer Science"}],"research experience":[{"name":"MIFA Lab, SJTU","position":"Research Intern","url":"https://huanglab.feishu.cn/docx/T11adQglboDFCaxXDuvcRqnpnQg","startDate":"2024.07","endDate":"present","summary":"Multimodal Foundation Model, Continual Learning"},{"name":"CoPhi Lab, SJTU","position":"Research Intern","url":"http://linyun.info/team.html","startDate":"2024.09","endDate":"present","summary":"Training Dynamic, Code Retrieval"}],"awards":[{"title":"Zhiyuan Honor Awards (Top 10% in SJTU)","date":"2023,2024"},{"title":"The Third Prize of Academic Scholarship (Top 30% in major)","date":"2024"}],"publications":[{"name":"Enhanced Continual Learning of Vision-Language Models with Model Fusion","publisher":"Haoyuan Gao, Zicong Zhang, Yuqi Wei, Linglan Zhao, Guilin Li, Yexin Li, Linghe Kong, Weiran Huang","releaseDate":"2025.03","url":"https://openreview.net/pdf?id=EAvuWKHhtq","summary":"The 13th International Conference on Learning Representations SCOPE Workshop"}],"skills":[{"name":"Programming","keywords":["C/C++","Python","Rust"]},{"name":"Technologies","keywords":["Git","Latex","Pytorch","Cmake","Linux","Numpy","Matplotlib"]}],"languages":[{"language":"Mandarin","fluency":"Native speaker","icon":""},{"language":"English","fluency":"CET-6(600pts)","icon":""}],"interests":[{"name":"Sports","icon":"fa-solid fa-tag","keywords":["running","tennis","street dance"]}],"projects":[{"name":"Continual Learning Framworks for VLMs","highlights":["Designed a continual learning framework for VLMs by introducing model fusion","Deployed a pipeline and conducted extensive experiments on multiple benchmarks, achieving up to 2% improvement over other state-of-the-art continual learning methods. "],"startDate":"2024.7","endDate":"2025.1"}]}